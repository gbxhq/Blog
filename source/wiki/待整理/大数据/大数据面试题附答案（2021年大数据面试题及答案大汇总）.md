# 大数据hhhh题附答案（2023年大数据hhhh题及答案大汇总）

大数据hhhh题及答案【最新版】大数据高级hhhh题大全(2021版)，发现网上很多大数据hhhh题及答案整理都没有答案，所以花了很长时间搜集，本套大数据hhhh题大全，大数据hhhh题大汇总，有大量经典的大数据hhhh题以及答案，包含大数据语言常见hhhh题、大数据工程师高级hhhh题及一些大厂大数据开发hhhh宝典，hhhh经验技巧等，应届生，实习生，企业工作过的，都可参考学习!

## 这套大数据hhhh题汇总大全，希望对大家有帮助哈~ 

## 博主已将以下这些hhhh题整理成了一个大数据hhhh手册，是PDF版的


### 全部答案，更新日期：2023年6月11日，直接下载吧！
### 下载链接：[高清172份，累计 7701 页大厂hhhh题  PDF](https://gitee.com/souyunku/DevBooks/blob/master/docs/index.md)


### [1、combiner出现在哪个过程](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#1combiner出现在哪个过程)  


出现在map阶段的map方法后，shuffle过程


### [2、是否可以在Windows上运行Hadoop？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#2是否可以在windows上运行hadoop)  


你最好不要这么做，Red Hat Linux或者是Ubuntu才是Hadoop的最佳操作系统。在Hadoop安装中，Windows通常不会被使用，因为会出现各种各样的问题。因此，Windows绝对不是Hadoop的推荐系统。



### [3、请你用最熟悉的语言编写mapreduce，计算第四列每个元素出现的个数](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#3请你用最熟悉的语言编写mapreduce计算第四列每个元素出现的个数)  




```
public classWordCount1 {

public static final String INPUT_PATH ="hdfs://hadoop0:9000/in";

public static final String OUT_PATH ="hdfs://hadoop0:9000/out";

public static void main(String[] args)throws Exception {

      Configuration conf = newConfiguration();

      FileSystem fileSystem =FileSystem.get(conf);

      if(fileSystem.exists(newPath(OUT_PATH))){}

      fileSystem.delete(newPath(OUT_PATH),true);

      Job job = newJob(conf,WordCount1.class.getSimpleName());

      //1.0读取文件，解析成key,value对

      FileInputFormat.setInputPaths(job,newPath(INPUT_PATH));

      //2.0写上自己的逻辑，对输入的可以，value进行处理，转换成新的key,value对进行输出

      job.setMapperClass(MyMapper.class);

      job.setMapOutputKeyClass(Text.class);

      job.setMapOutputValueClass(LongWritable.class);

      //3.0对输出后的数据进行分区

      //4.0对分区后的数据进行排序，分组，相同key的value放到一个集合中

      //5.0对分组后的数据进行规约

      //6.0对通过网络将map输出的数据拷贝到reduce节点

      //7.0 写上自己的reduce函数逻辑，对map输出的数据进行处理

      job.setReducerClass(MyReducer.class);

      job.setOutputKeyClass(Text.class);

      job.setOutputValueClass(LongWritable.class);

      FileOutputFormat.setOutputPath(job,new Path(OUT_PATH));

      job.waitForCompletion(true);

}

static class MyMapper extendsMapper<LongWritable, Text, Text, LongWritable>{

      @Override

      protected void map(LongWritablek1, Text v1,

                    org.apache.hadoop.mapreduce.Mapper.Contextcontext)

                    throws IOException,InterruptedException {

             String[] split =v1.toString().split("\t");

             for(String words :split){

                    context.write(split[3],1);

             }

      }

}

static class MyReducer extends Reducer<Text,LongWritable, Text, LongWritable>{



      protected void reduce(Text k2,Iterable<LongWritable> v2,

                    org.apache.hadoop.mapreduce.Reducer.Contextcontext)

                    throws IOException,InterruptedException {

             Long count = 0L;

             for(LongWritable time :v2){

                    count += time.get();

             }

             context.write(v2, newLongWritable(count));

      }

}

}
```


### [4、什么是spark](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#4什么是spark)  


基于内存计算发数据分析引擎，提高在大数据环境下数处理的实时性，spark仅涉及数据计算


### [5、HDFS读取文件的步骤](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#5hdfs读取文件的步骤)  


**1、** Client向NameNode请求下载某文件。

**2、** NameNode向Client返回文件的元数据。

**3、** Client向DataNode1请求访问读数据Block_1.

**4、** DataNode1向Client传输数据。

**5、** Client向DataNode2请求访问读数据Block_2.

**6、** DataNode2向Client传输数据。


### [6、hbase内部机制是什么](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#6hbase内部机制是什么)  


Hbase是一个能适应联机业务的数据库系统

物理存储：hbase的持久化数据是存放在hdfs上

存储管理：一个表是划分为很多region的，这些region分布式地存放在很多regionserver上

Region内部还可以划分为store，store内部有memstore和storefile

版本管理：hbase中的数据更新本质上是不断追加新的版本，通过compact操作来做版本间的文件合并

Region的split

集群管理：zookeeper + hmaster（职责） + hregionserver（职责）


### [7、flush的过程](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#7flush的过程)  


flush是在内存的基础上进行的，首先写入文件的时候，会先将文件写到内存中，当内存写满的时候，一次性的将文件全部都写到硬盘中去保存，并清空缓存中的文件，


### [8、简述hadoop spark storm hive的特点及使用场景](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#8简述hadoop-spark-storm-hive的特点及使用场景)  


hadoop是一种分布式系统基础架构当处理海量数据对的程序，开始要求高可靠，高扩展，高效，低容错，低成本场景

MapReduce是一种编程模型，用于大规模数据集的并行计算，目前日志分析居多

spark拥有mr的所具有的优点；但不同于mr的是job中间输出的结果可以保存到内存中，从而不需要读写hdfs，由此spark能更好的适用于数据挖掘与机器学习等需要迭代式计算，极大的提高效率的场景

storm ：一个分布式实时计算系统storm是一个任务并行连续计算引擎，storm并不在hadoop集群运行，他是用Zookeeper的和自己的 主从 工作进程，协调拓扑和工作者状态

hive 数据仓库

hbase：数据量大，传统数据库无法胜任，联机业务功能开发，离线数据分析


### [9、mapreduce作业，不让reduce输出，用什么代替reduce的功能。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#9mapreduce作业不让reduce输出用什么代替reduce的功能。)  


hive如何调优

hive最终都会转化为mapreduce的job来运行，要想hive调优，实际上就是mapreduce调优，可以有下面几个方面的调优。解决收据倾斜问题，减少job数量，设置合理的map和reduce个数，对小文件进行合并，优化时把握整体，单个task最优不如整体最优。按照一定规则分区。


### [10、简述hive中的虚拟列的作用？使用它注意事项](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#10简述hive中的虚拟列的作用使用它注意事项)  


三个虚拟列

INPUT_FILE_NAME：mapper任务的输出文件名

BLOCK_OFFSET_INSIDE_FILE：当前全局文件偏移量，对于快压缩文件，就是当前快的文件偏移量，及当前块的第一个字节在文件中的偏移量

ROW_OFFSET_INSIDE_BLOCK，默认不开启，设置hive.exec.rowoffset为true可用，可以用来排查有问题的输入数据


### [11、Kafka怎么保证消息不丢失机制](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#11kafka怎么保证消息不丢失机制)  

### [12、这会导致安全问题吗？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#12这会导致安全问题吗)  

### [13、如何确定hadoop集群的健康状态](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#13如何确定hadoop集群的健康状态)  

### [14、Hbase宕机如何处理](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#14hbase宕机如何处理)  

### [15、举一个例子说明mapreduce是怎么运行的。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#15举一个例子说明mapreduce是怎么运行的。)  

### [16、MapReduce优化经验](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#16mapreduce优化经验)  

### [17、现场出问题测试mapreduce掌握情况和hive的ql语言掌握情况](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#17现场出问题测试mapreduce掌握情况和hive的ql语言掌握情况)  

### [18、List与set的区别](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#18list与set的区别)  

### [19、当你输入hadoopfsck 造成“connection refused java exception’”时，系统究竟发生了什么？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#19当你输入hadoopfsck-造成“connection-refused-java-exception’时系统究竟发生了什么)  

### [20、Hive与关系型数据库的关系？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#20hive与关系型数据库的关系)  

### [21、storm怎么保障消息不丢失](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#21storm怎么保障消息不丢失)  

### [22、请说明hive中Sort By、Order By、Cluster By，Distribute By各代表什么意思？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#22请说明hive中sort-byorder-bycluster-bydistribute-by各代表什么意思)  

### [23、Spark的数据本地性有哪几种？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#23spark的数据本地性有哪几种)  

### [24、Flume的工作及时是什么？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#24flume的工作及时是什么)  

### [25、在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#25在25亿个整数中找出不重复的整数注内存不足以容纳这25亿个整数。)  

### [26、HDFS写文件的步骤：](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#26hdfs写文件的步骤：)  

### [27、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#27sqoop在导入到mysql中如果不重复导入数据如果数据存在问题sqoop如何处理)  

### [28、Slaves由什么组成？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#28slaves由什么组成)  

### [29、hadoop数据倾斜及解决办法](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#29hadoop数据倾斜及解决办法)  

### [30、map-reduce程序运行的时候会有什么比较常见的问题](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#30map-reduce程序运行的时候会有什么比较常见的问题)  

### [31、SSH工作的端口号是？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#31ssh工作的端口号是)  

### [32、RAM的溢出因子是？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据hhhh题附答案（2021年大数据hhhh题及答案大汇总）.md#32ram的溢出因子是)  






## [全部答案，更新日期：2023年6月11日，直接下载吧！](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)

### 下载链接：[全部答案，整理好了](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/daan.md)




## [新增：高清PDF：172份，7701页，最新整理](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)
