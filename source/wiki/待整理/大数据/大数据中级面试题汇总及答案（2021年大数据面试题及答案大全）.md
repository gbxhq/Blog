# 大数据中级hhhh题汇总及答案（2023年大数据hhhh题及答案大全）

大数据hhhh题及答案【最新版】大数据高级hhhh题大全(2021版)，发现网上很多大数据hhhh题及答案整理都没有答案，所以花了很长时间搜集，本套大数据hhhh题大全，大数据hhhh题大汇总，有大量经典的大数据hhhh题以及答案，包含大数据语言常见hhhh题、大数据工程师高级hhhh题及一些大厂大数据开发hhhh宝典，hhhh经验技巧等，应届生，实习生，企业工作过的，都可参考学习!

## 这套大数据hhhh题汇总大全，希望对大家有帮助哈~ 

## 博主已将以下这些hhhh题整理成了一个大数据hhhh手册，是PDF版的


### 全部答案，更新日期：2023年6月11日，直接下载吧！
### 下载链接：[高清172份，累计 7701 页大厂hhhh题  PDF](https://gitee.com/souyunku/DevBooks/blob/master/docs/index.md)


### [1、hive数仓开发的基本流程](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#1hive数仓开发的基本流程)  


**从业务系统获取数据**

sqoop从关系型数据库中 导入数据到hdfs中，也可以将hdfs数据倒进到关系型数据库中

flume:采集数据存放到hdfs中

ftp：从文件服务器上下载分析所需的数据

数据存储

分为ods 层 ，dw层，da层

源数据层：没有格式化的数据，不利于分析

数据仓库层：来自ODS层要经过ETL的过程 格式统一 数据规则

数据应用层：使用DW层，数据使用者

写sql

配置调度系统

导出数据展示


### [2、“jps”命令的用处？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#2“jps命令的用处)  


这个命令可以检查Namenode、Datanode、Task Tracker、 Job Tracker是否正常工作。


### [3、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#3宕机分为hmaster宕机和hregisoner宕机如果是hregisoner宕机hmaster会将其所管理的region重新分布到其他活动的regionserver上由于数据和日志都持久在hdfs中该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。)  


如果是HMaster宕机，HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。即ZooKeeper会保证总会有一个HMaster在对外提供服务。


### [4、hadoop和spark都是并行计算，那么他们有什么相同和区别？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#4hadoop和spark都是并行计算那么他们有什么相同和区别)  


两者都使用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束。

Spark用户提交的任务称为application，一个application对应一个SparkContext，app中存在多个job，没触发一个action操作就会产生一个job。

这些job可以并行或者串行执行，每个job有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和application一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算的。

Hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系。

Spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作join，groupby等，而且通过DAG图可以实现良好的容错。


### [5、创建topic：](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#5创建topic：)  


./Kafka-topic.sh --create --partition 3 --replication-factor 2 --topic test --zookeeper node01:2181,node2:2181,node3:2181


### [6、请描述如何解决Hbase中region太小和region太大带来的结果。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#6请描述如何解决hbase中region太小和region太大带来的结果。)  


Region过大会发生多次compaction，将数据读一遍并写一遍到hdfs上，占用io，region过小会造成多次split，region会下线，影响访问服务，调整hbase.heregion.max.filesize为256m。


### [7、解释下hbase实时查询原理](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#7解释下hbase实时查询原理)  


实时查询，可疑人物是从内存中查询，一般响应为1秒内。

Hbase机制是数据先写入到内存中，当数据达到一定量，再写入磁盘中，在内存中不进行数据的更新和合并操作，值增加数据，使得用户的写操作值进入内存中可以立即返回，保证了Hasee的高性能


### [8、RDD 是什么](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#8rdd-是什么)  


弹性分布式数据集，是spark中最基本的数据抽象，可以存于内存中或者磁盘中，分布式存储可用于分布式计算

一个不可变，可分区，里面的数据可并行计算的集合


### [9、简单说一下hadoop的map-reduce模型](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#9简单说一下hadoop的map-reduce模型)  


首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合，使用的是hadoop内置的数据类型，如Text，Longwritable等。

将键值对集合输入mapper进行业务处理过程，将其转化成需要的key-value再输出。

之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getPartition方法来自定义分区规则。

之后会对key进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则。

之后进行一个combiner归约操作，就是一个本地的reduce预处理，以减小shuffle，reducer的工作量。

Reduce task会用过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job。


### [10、hadoop的TextInputFormat作用是什么，如何自定义实现？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#10hadoop的textinputformat作用是什么如何自定义实现)  


InputFormat会在map操作之前对数据进行两方面的预处理。

1.是getSplits，返回的是InputSplit数组，对数据进行Split分片，每片交给map操作一次。

2.是getRecordReader，返回的是RecordReader对象，对每个Split分片进行转换为key-value键值对格式传递给map常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值。

3.自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法在createRecordReader中可以自定义分隔符。


### [11、Kafka的消息发送](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#11kafka的消息发送)  

### [12、为什么SSH本地主机需要密码？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#12为什么ssh本地主机需要密码)  

### [13、描述一下hadoop中，有哪些地方使用到了缓存机制，作用分别是什么？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#13描述一下hadoop中有哪些地方使用到了缓存机制作用分别是什么)  

### [14、伪分布模式中的注意点？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#14伪分布模式中的注意点)  

### [15、hive的原数据存储](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#15hive的原数据存储)  

### [16、查看所有的topic](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#16查看所有的topic)  

### [17、hive 跟hbase的区别](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#17hive-跟hbase的区别)  

### [18、为什么会产生RDD](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#18为什么会产生rdd)  

### [19、HBase写数据的原理是什么？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#19hbase写数据的原理是什么)  

### [20、请描述一下开发过程中如何对上面的程序进行性能分析，对性能分析进行优化的过程。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#20请描述一下开发过程中如何对上面的程序进行性能分析对性能分析进行优化的过程。)  

### [21、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#21有一个1g大小的一个文件里面每一行是一个词词的大小不超过16字节内存限制大小是1m。返回频数最高的100个词。)  

### [22、HBase简单读写流程？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#22hbase简单读写流程)  

### [23、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#23上千万或上亿数据有重复统计其中出现次数最多的前n个数据。)  

### [24、数据导入hive的方式](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#24数据导入hive的方式)  

### [25、Fsck的全名？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#25fsck的全名)  

### [26、MapReduce如何优化](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#26mapreduce如何优化)  

### [27、sqoop在导入数据到MySQL中，如何不重复导入数据，如果存在数据问题，sqoop如何处理？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#27sqoop在导入数据到mysql中如何不重复导入数据如果存在数据问题sqoop如何处理)  

### [28、Hive生产环境中为什么建议使用外部表？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#28hive生产环境中为什么建议使用外部表)  

### [29、hdfs的体系结构](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#29hdfs的体系结构)  

### [30、请列出正常的hadoop集群中hadoop都分别需要启动 哪些进程，他们的作用分别都是什么，请尽量列的详细一些。](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#30请列出正常的hadoop集群中hadoop都分别需要启动-哪些进程他们的作用分别都是什么请尽量列的详细一些。)  

### [31、什么是队列](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#31什么是队列)  

### [32、介绍一下join操作优化经验？](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/大数据/大数据中级hhhh题汇总及答案（2021年大数据hhhh题及答案大全）.md#32介绍一下join操作优化经验)  






## [全部答案，更新日期：2023年6月11日，直接下载吧！](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)

### 下载链接：[全部答案，整理好了](https://gitee.com/souyunku/NewDevBooks/blob/master/docs/daan.md)




## [新增：高清PDF：172份，7701页，最新整理](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)
